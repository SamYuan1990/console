name: CVE to Deployment
on: # yamllint disable-line rule:truthy
  push:
    branches: [master]
  pull_request:

jobs:
  test-cvetodeployment:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout action
        id: checkout
        uses: actions/checkout@v4
      - uses: actions/setup-go@v5
      - name: generate CVE.json
        run: |
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b ./
          go install github.com/devops-kung-fu/bomber@latest 
          ./syft scan . -o cyclonedx-json -vv  > sbom.json 
          cat sbom.json
          bomber scan ./sbom.json --output=json --debug > cve.json
          cat cve.json
      #- name: use this action to generate suggestion for deployment settings
      #  id: Lint_with_LLM
      #  uses: SamYuan1990/OpenAI_CodeAgent-action@main
      #  with:
      #    baseURL: https://api.deepseek.com
      #    apiKey: dummy
      #    model: deepseek-chat
      #    dirpath: '/workdir'
      #    deploymentfile: /workdir/manifests/k8s/config/exporter/exporter.yaml
      #    runType: CVE2Deployment
      #    dryRun: ${{ inputs.dryrun }}
      #    githubIssueReport: true
      #- name: output check
      #  shell: bash
      #  run: |
      #    echo '${{ steps.Lint_with_LLM.outputs.LLMresponse }}'
      #    echo '${{ steps.Lint_with_LLM.outputs.final_prompt }}'
      #    echo '${{ steps.Lint_with_LLM.outputs.avg_prompt_precent }}'
      #    echo '${{ steps.Lint_with_LLM.outputs.avg_content_precent }}'
      #    echo '${{ steps.Lint_with_LLM.outputs.avg_time_usage }}'
      #    echo '${{ steps.Lint_with_LLM.outputs.avg_inputToken }}'
      #    echo '${{ steps.Lint_with_LLM.outputs.avg_outputToken }}'

      #- name: Create new issue
      #  uses: imjohnbo/issue-bot@v3
      #  if: ${{ inputs.dryrun == false }}
      #  with:
      #    title: CVE cross check with deployment
      #    body: |-
      #      :wave: Hi maintainers, here is LLM's deployment suggested according to your CVSS scan result.
      #      ${{ steps.Lint_with_LLM.outputs.LLMresponse }}
